{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment2_preprocess.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Zn0udUKBMUUW",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PZdSH-_JMp9K",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QlyU_E6GM3gi",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from googleapiclient.discovery import build\n",
        "drive_service = build('drive', 'v3')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n_WasbU4NBnK",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "def getFile(file_name, target_id):\n",
        "\n",
        "  # 1. Authenticate and create the PyDrive client.\n",
        "  auth.authenticate_user()\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.credentials = GoogleCredentials.get_application_default()\n",
        "  drive = GoogleDrive(gauth)\n",
        "\n",
        "  #2. Get the file\n",
        "  downloaded = drive.CreateFile({'id':target_id}) # replace the id with id of file you want to access\n",
        "  downloaded.GetContentFile(file_name)  \n",
        "  print 'done downloading '+ file_name"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KzRygIKFNNB2",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "number_videos = 1\n",
        "file_names = ['Sadhguru1.mp4', 'Sadhguru2.mp4', 'Sadhguru3.mp4', 'Noise.mp4', 'Raman1.mp4', 'Raman2.mp4', 'Raman3.mp4', 'Sandeep1.mp4', 'Sandeep2.mp4', 'Sandeep3.mp4', 'Saurabh1.mp4', 'Saurabh2.mp4', 'Saurabh3.mp4', 'Shailendra1.mp4', 'Shailendra2.mp4', 'Shailendra3.mp4', 'AtulKhatri1.mp4', 'AtulKhatri2.mp4', 'AtulKhatri3.mp4']\n",
        "target_ids = ['1ryeJ3KZ8qHlodgkPhEzNqTTXTWV9whca', '13v9kZQfy0zezSA2NCTG5QyFfamsD_2lV', '15rK_Com561Pjx9ny32153om7ISz0QYFC', '16ydLEDwbrSsZz00ZkjwWz5Vnwd8TJ9tk', '1-4d04MCVw-HIyDZdisl0krclVcSTg_MV', '1XKreuwC29MuyqPC0A_hR6rw6F9qe1N2n', '1IxsYvvvAC61qL3j_-P6akyJHhVWHb1T1',\n",
        "             '1v0Rt0sc_zm4KXAQxq3fV1zc3esvNE9Nd', '1RAUaXKcYKVWzNi53n3wWXr31UCMI2Tqv', '1qLCIWAnHHpZ4U4Mvg6jskEAONNAY2Oo8', '13B7B30ChGk9mR1dXO1YEfJnPZsKz1q0Y', '1qsqgB33wz82jE83jbiKdnH97TS3L0bao', '1f0Xy4G1T6jcBV4U8q9EPW6BzzlK7jqzx', '1yWCIoPxCgm0yK-vEBJIxMP1IOM-Bb6yY',\n",
        "             '1oaj_4LvX9wkOPRPoxUQA6b8ZXlmRlDXm', '1ULbUKnjbLXfBGOiwenYvnC4lQCEr2e6O', '1c5bzApuR7xU_6BLH5XYypVbg99MeWBlK', '1j_i_hAse1ukdekp6tWxZZdbemY0Suk8H', '10MJrxoB5WuvXDMPfY8HwdlMqet1fdSkT']\n",
        "\n",
        "\n",
        "#file_names = ['Sadhguru.mp4', 'AtulKhatri.mp4', 'Raman.mp4', 'Shailendra.mp4', 'SaurabhPant.mp4', 'Sandeep.mp4', 'Noise.mp4']\n",
        "#target_ids = ['1y4wJ9hEt-bzIj83I-pDXWt5NjaEp-51z', '1rZmgS0Y8BH4WZpWENi_87yHydvvBYNoO', '1XmBV80oyHFmNnfujVZ20NzQLJtNrOAkN', '1hFiE2xFO1MccJ-DK8xy8_p-Y0iw5FIew', '1Jt9C51FmPpgicG4vw6QvZiCyQUvkn-RU','1Hvttqk8e9qahngjORwJThX_3VDHAZnHC','1oBwnoBPUiIl7dkF2_pnkN71rtI5KGxV8']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YPAxXK7bOgl0",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "86154a5c-42f8-4297-a494-761b27607477",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1521979298408,
          "user_tz": -330,
          "elapsed": 19496,
          "user": {
            "displayName": "Rishubh Parihar",
            "photoUrl": "//lh6.googleusercontent.com/-QqGRLLfgGHQ/AAAAAAAAAAI/AAAAAAAAAOI/-iCR6EfetGg/s50-c-k-no/photo.jpg",
            "userId": "107583305779630309300"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "for i in range(0, len(file_names)):\n",
        "    file_name = file_names[i]\n",
        "    file_id = target_ids[i]\n",
        "    getFile(file_name,file_id)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done downloading Sadhguru1.mp4\n",
            "done downloading Sadhguru2.mp4\n",
            "done downloading Sadhguru3.mp4\n",
            "done downloading Noise.mp4\n",
            "done downloading Raman1.mp4\n",
            "done downloading Raman2.mp4\n",
            "done downloading Raman3.mp4\n",
            "done downloading Sandeep1.mp4\n",
            "done downloading Sandeep2.mp4\n",
            "done downloading Sandeep3.mp4\n",
            "done downloading Saurabh1.mp4\n",
            "done downloading Saurabh2.mp4\n",
            "done downloading Saurabh3.mp4\n",
            "done downloading Shailendra1.mp4\n",
            "done downloading Shailendra2.mp4\n",
            "done downloading Shailendra3.mp4\n",
            "done downloading AtulKhatri1.mp4\n",
            "done downloading AtulKhatri2.mp4\n",
            "done downloading AtulKhatri3.mp4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2GryXLMbPPQw",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "6b4e710b-71f8-4a19-e920-42b12417fb2a",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1521979299656,
          "user_tz": -330,
          "elapsed": 1190,
          "user": {
            "displayName": "Rishubh Parihar",
            "photoUrl": "//lh6.googleusercontent.com/-QqGRLLfgGHQ/AAAAAAAAAAI/AAAAAAAAAOI/-iCR6EfetGg/s50-c-k-no/photo.jpg",
            "userId": "107583305779630309300"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AtulKhatri1.mp4  model.json  Sadhguru1.mp4  Sandeep3.mp4   SaurabhPant.mp4\r\n",
            "AtulKhatri2.mp4  Noise.mp4   Sadhguru2.mp4  Sandeep.mp4    Shailendra1.mp4\r\n",
            "AtulKhatri3.mp4  Raman1.mp4  Sadhguru3.mp4  Saurabh1.mp4   Shailendra2.mp4\r\n",
            "AtulKhatri.mp4\t Raman2.mp4  Sadhguru.mp4   Saurabh2.mp4   Shailendra3.mp4\r\n",
            "datalab\t\t Raman3.mp4  Sandeep1.mp4   Saurabh3.mp4   Shailendra.mp4\r\n",
            "model.h5\t Raman.mp4   Sandeep2.mp4   Saurabh3.,mp4\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6OdUF6ICPSb4",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from keras.models import Sequential \t\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\t\n",
        "from keras.layers import Convolution2D, MaxPooling2D \t\n",
        "from keras.utils import np_utils\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dense\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import model_from_json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NVyL2QBEran4",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def extract_data_next(index, num_frames, file_names, labels, X, Y):\n",
        "  for i in range(0,len(labels)):\n",
        "    print(\"index \",i)\n",
        "    name = file_names[i]\n",
        "    label = labels[i]\n",
        "\n",
        "    cap = cv2.VideoCapture(name)\n",
        "    t = index\n",
        "    while(cap.isOpened() and t < index + num_frames):\n",
        "      t += 1\n",
        "      #print(\"index \", t)\n",
        "      ret, frame = cap.read()\n",
        "        if (ret):\n",
        "        frame_downsample = cv2.resize(frame, (240, 180))\n",
        "        #cv2.imshow('frame',frame_downsample)\n",
        "        X.append(frame_downsample)\n",
        "        Y.append(label)\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "          break\n",
        "      else:\n",
        "        break\n",
        "\n",
        "    print(name, \" done. Number of frames = \",t)\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "  X = np.asarray(X)\n",
        "  Y = np.asarray(Y)\n",
        "\n",
        "  X = np.reshape(X, (X.shape[0],180, 240, 3))\n",
        "  Y = np.reshape(Y, (Y.shape[0],1))\n",
        "\n",
        "  X = X.astype('float32')\n",
        "  X = X/255.0\n",
        "  Y = Y\n",
        "\n",
        "  X,Y = shuffle(X, Y, random_state = 1)\n",
        "\n",
        "  print(\"X.shape \",X.shape)\n",
        "  print(\"Y.shape \",Y.shape)\n",
        "\n",
        "  Y = np_utils.to_categorical(Y, 7)\n",
        "  return X,Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fOFuFZZJrdhu",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def create_CNN(height, width, depth, classes):\n",
        "\tinputShape = (height, width, depth)\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(20, (5, 5), padding=\"same\", input_shape=inputShape))\n",
        "\tmodel.add(Activation(\"relu\"))\n",
        "\tmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\t\n",
        "\t\n",
        "\t#model.add(Conv2D(50, (5, 5), padding=\"same\"))\n",
        "\t#model.add(Activation(\"relu\"))\n",
        "\t#model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(500))\n",
        "\tmodel.add(Activation(\"relu\"))\n",
        "\n",
        "\t# softmax classifier\n",
        "\tmodel.add(Dense(classes))\n",
        "\tmodel.add(Activation(\"softmax\"))\n",
        "\n",
        "\t# return the constructed network architecture\n",
        "\treturn model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kZTPpSR6rhJY",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def train_model():\n",
        "  file_names = ['AtulKhatri1.mp4', 'AtulKhatri2.mp4', 'AtulKhatri3.mp4', 'Raman1.mp4', 'Raman2.mp4', 'Raman3.mp4', 'Sadhguru1.mp4' , 'Sadhguru2.mp4', 'Sadhguru3.mp4',\n",
        "                'Saurabh1.mp4', 'Saurabh2.mp4', 'Saurabh3.mp4', 'Shailendra1.mp4', 'Shailendra2.mp4', 'Shailendra3.mp4', 'Noise.mp4', 'Sandeep1.mp4', 'Sandeep2.mp4', 'Sandeep3.mp4']\n",
        "  labels = [0,0,0,1,1,1,2,2,2,3,3,3,4,4,4,5,6,6,6]\n",
        "  has_data = True\n",
        "  index = 0\n",
        "  while(has_data and index < 10000):\n",
        "    X,Y = [],[]\n",
        "    X,Y = extract_data_next(index, 200, file_names, labels, X, Y)\n",
        "    (X_train, X_test, Y_train, Y_test) = train_test_split(X, Y, test_size = 0.30, random_state=42)\t\n",
        "    print(\"Xtrain.shape \", X_train.shape)\n",
        "    print(\"Ytrain.shape \", Y_train.shape)\n",
        "    print(\"Xtest.shape \", X_test.shape)\n",
        "    print(\"Ytest.shape \", Y_test.shape)\n",
        "\n",
        "    height = 180\n",
        "    width = 240\n",
        "    depth = 3\n",
        "    classes = 7\n",
        "    model = None\n",
        "\n",
        "    if (index == 0):\n",
        "      new_model = create_CNN(height, width, depth, classes)\n",
        "      model = new_model\n",
        "    else:\n",
        "      # load json and create model\n",
        "      json_file = open('model.json', 'r')\n",
        "      loaded_model_json = json_file.read()\n",
        "      json_file.close()\n",
        "      loaded_model = model_from_json(loaded_model_json)\n",
        "      # load weights into new model\n",
        "      loaded_model.load_weights(\"model.h5\")\n",
        "      print(\"Loaded model from disk\")\n",
        "      model = loaded_model\n",
        "\n",
        "\n",
        "    print(\"[INFO] compiling model...\")\n",
        "    opt = Adam(lr=1e-3, decay=1e-3/ 25)\n",
        "    model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
        "\n",
        "    # train the network\n",
        "    aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1,\n",
        "      height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
        "      horizontal_flip=True, fill_mode=\"nearest\")\n",
        "    print(\"[INFO] training network...\")\n",
        "    H = model.fit_generator(aug.flow(X_train, Y_train, batch_size = 32),\n",
        "      validation_data=(X_test, Y_test), steps_per_epoch=len(X_train) // 32,\n",
        "      epochs=1, verbose=1)\n",
        "\n",
        "    # save the model to disk\n",
        "    print(\"[INFO] serializing network...\")\n",
        "    # serialize model to JSON\n",
        "\n",
        "    model_json = model.to_json()\n",
        "    with open(\"model.json\", \"w\") as json_file:\n",
        "        json_file.write(model_json)\n",
        "    # serialize weights to HDF5\n",
        "    model.save_weights(\"model.h5\")\n",
        "    print(\"Saved model to disk\")\n",
        "    index += 200\n",
        "\t\t\t\t \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v4NbrE1prrqw",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 3294
        },
        "outputId": "43352e03-9bb0-4313-e15a-25b5aa6a1c76",
        "executionInfo": {
          "status": "error",
          "timestamp": 1521980533693,
          "user_tz": -330,
          "elapsed": 21349,
          "user": {
            "displayName": "Rishubh Parihar",
            "photoUrl": "//lh6.googleusercontent.com/-QqGRLLfgGHQ/AAAAAAAAAAI/AAAAAAAAAOI/-iCR6EfetGg/s50-c-k-no/photo.jpg",
            "userId": "107583305779630309300"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "train_model()"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('index ', 0)\n",
            "('AtulKhatri.mp4', ' done. Number of frames = ', 500)\n",
            "('index ', 1)\n",
            "('Raman.mp4', ' done. Number of frames = ', 500)\n",
            "('index ', 2)\n",
            "('Sadhguru.mp4', ' done. Number of frames = ', 500)\n",
            "('index ', 3)\n",
            "('SaurabhPant.mp4', ' done. Number of frames = ', 500)\n",
            "('index ', 4)\n",
            "('Shailendra.mp4', ' done. Number of frames = ', 500)\n",
            "('index ', 5)\n",
            "('Noise.mp4', ' done. Number of frames = ', 500)\n",
            "('index ', 6)\n",
            "('Sandeep.mp4', ' done. Number of frames = ', 500)\n",
            "('X.shape ', (3500, 180, 240, 3))\n",
            "('Y.shape ', (3500, 1))\n",
            "('Xtrain.shape ', (2450, 180, 240, 3))\n",
            "('Ytrain.shape ', (2450, 7))\n",
            "('Xtest.shape ', (1050, 180, 240, 3))\n",
            "('Ytest.shape ', (1050, 7))\n",
            "[INFO] compiling model...\n",
            "[INFO] training network...\n",
            "Epoch 1/1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-102-4dc2ba0c028a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-101-8de143288b43>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m     H = model.fit_generator(aug.flow(X_train, Y_train, batch_size = 32),\n\u001b[1;32m     46\u001b[0m       \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m       epochs=1, verbose=1)\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;31m# save the model to disk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1274\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1275\u001b[0m                                         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1276\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1278\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2222\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2223\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2224\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2226\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1881\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1883\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1885\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2474\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2475\u001b[0m         \u001b[0mfetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2476\u001b[0;31m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m   2478\u001b[0m                               **self.session_kwargs)\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_initialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0muninitialized_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                     \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muninitialized_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m     \u001b[0;31m# hack for list_devices() function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;31m# list_devices() function is not available under tensorflow r1.3.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1137\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1355\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1356\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1374\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor of shape [216000,500] and type float\n\t [[Node: training_24/Adam/zeros_2 = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [216000,500] values: [0 0 0]...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\nCaused by op u'training_24/Adam/zeros_2', defined at:\n  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2828, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-102-4dc2ba0c028a>\", line 1, in <module>\n    train_model()\n  File \"<ipython-input-101-8de143288b43>\", line 47, in train_model\n    epochs=1, verbose=1)\n  File \"/usr/local/lib/python2.7/dist-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/keras/models.py\", line 1276, in fit_generator\n    initial_epoch=initial_epoch)\n  File \"/usr/local/lib/python2.7/dist-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/keras/engine/training.py\", line 2080, in fit_generator\n    self._make_train_function()\n  File \"/usr/local/lib/python2.7/dist-packages/keras/engine/training.py\", line 990, in _make_train_function\n    loss=self.total_loss)\n  File \"/usr/local/lib/python2.7/dist-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/keras/optimizers.py\", line 457, in get_updates\n    ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n  File \"/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py\", line 692, in zeros\n    v = tf.zeros(shape=shape, dtype=tf_dtype, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_ops.py\", line 1570, in zeros\n    output = fill(shape, constant(zero, dtype=dtype), name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 1713, in fill\n    \"Fill\", dims=dims, value=value, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 3271, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1650, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor of shape [216000,500] and type float\n\t [[Node: training_24/Adam/zeros_2 = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [216000,500] values: [0 0 0]...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n"
          ]
        }
      ]
    }
  ]
}